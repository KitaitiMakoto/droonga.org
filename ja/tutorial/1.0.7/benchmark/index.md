---
title: "DroongaとGroongaのベンチマークの取り方"
layout: ja
---

{% comment %}
##############################################
  THIS FILE IS AUTOMATICALLY GENERATED FROM
  "_po/ja/tutorial/1.0.7/benchmark/index.po"
  DO NOT EDIT THIS FILE MANUALLY!
##############################################
{% endcomment %}


* TOC
{:toc}

<!--
this is based on https://github.com/droonga/presentation-droonga-meetup-1-introduction/blob/master/benchmark/README.md
-->

## チュートリアルのゴール

[Droonga][]クラスタのベンチマークを測定し、[Groonga][groonga]での結果と比較するまでの、一連の手順を学ぶこと。

## 前提条件

* [Ubuntu][]または[CentOS][]のサーバの操作に関する基本的な知識と経験があること。
* [Groonga][groonga]をHTTP経由で操作する際の基本的な知識と経験があること。
* [Droonga][]クラスタの構築手順について基本的な知識があること。
  このチュートリアルの前に、[「始めてみる」のチュートリアル](../groonga/)を完了しておいて下さい。

また、新しいDroongaクラスタのために以下の4つの[Ubuntu][] 14.04LTSのサーバがあると仮定します:

 * `192.168.100.50`
 * `192.168.100.51`
 * `192.168.100.52`
 * `192.168.100.53`

1つはクライアント用で、残りの3つはDroongaノード用です。

## ベンチマークの必要性について

DroongaはGroongaと互換性があるため、GroongaベースのアプリケーションをDroongaに移行することを検討することもあるでしょう。
そんな時は、実際に移行する前に、Droongaの性能を測定して、より良い移行先であるかどうかを確認しておくべきです。

もちろん、単にGroongaとDroongaの性能差を知りたいと思うこともあるでしょう。
ベンチマークによって、差を可視化することができます。


### ベンチマークツールはどのように性能を測定するのか

ベンチマークは、[drnbench]()というGemパッケージによって導入される`drnbench-request-response`コマンドで行うことができます。
このツールは、対象サービスのスループット性能、つまり、一度にどれだけの数のリクエストを捌けるかを計測します。
性能の指標は「*クエリ毎秒*（Queries Per Second, *qps*）」という単位で表されます。

例えば、あるGroongaサーバが1秒に10件のリクエストを処理できたとき、これを「10qps」と表現します。
10人のユーザ（クライアント）がいるのかもしれませんし、2人のユーザがそれぞれブラウザ上で5つのタブを開いているのかもしれません。
ともかく、「10qps」という数値は、1秒が経過する間にそのGroongaサーバが実際に10件のリクエストを受け付けて、レスポンスを返したということを意味します。

`drnbench-request-response`は、対象サービスの性能を以下のようにして計測します:

 1. マスタープロセスが仮想クライアントを1つ生成する。
    このクライアントは即座に動き始め、対象サービスに対して多数のリクエストを連続して頻繁に送り続ける。
 2. しばらくしたら、マスタープロセスがクライアントを終了させる。
    そして、実際に対象サービスによって処理されたリクエストの件数を集計し、結果を1クライアントの場合のqps値として報告する。
 3. マスタープロセスが仮想クライアントを2つ生成する。
    これらのクライアントはリクエストを送り始める。
 4. しばらくしたら、マスタープロセスがすべてのクライアントを終了させる。
    そして、実際に対象サービスに処理されたリクエストの件数を集計し、結果を2クライアントの場合のqps値として報告する。
 5. 3クライアントの場合、4クライアントの場合……と、クライアント数を増やしながら繰り返す。
 6. 最後に、マスタープロセスが結果のqps値とその他の情報をまとめたものを、以下のようなCSVファイルとして保存する:
    
    ~~~
    n_clients,total_n_requests,queries_per_second,min_elapsed_time,max_elapsed_time,average_elapsed_time,0,200
    1,164,5.466666666666667,0.002184631,1.951960432,0.1727086823963415,0,100.0
    2,1618,53.93333333333333,0.001466091,1.587372312,0.026789948272558754,0.12360939431396785,99.87639060568603
    4,4690,156.33333333333334,0.001065161,0.26070575,0.015224578191897657,0.042643923240938165,99.95735607675907
    6,6287,209.56666666666666,0.000923332,0.25709169,0.018191428254970568,0.09543502465404805,99.90456497534595
    8,6628,220.93333333333334,0.000979707,0.288406006,0.02557014875603507,0.030175015087507546,99.96982498491249
    10,7117,237.23333333333332,0.001235846,0.303093461,0.03160425060474918,0.1405086412814388,99.85949135871857
    12,7403,246.76666666666668,0.001111115,0.33163911,0.03792291040199917,0.09455626097528029,99.90544373902472
    14,7454,248.46666666666667,0.00151987,0.335161281,0.04522922885028168,0.174403005097934,99.82559699490207
    16,7357,245.23333333333332,0.000763487,0.356862003,0.05435767224085904,0.08155498165012913,99.91844501834987
    18,7494,249.8,0.001017168,0.378661333,0.061178927504003194,0.20016012810248196,99.79983987189752
    20,7506,250.2,0.001759464,0.404634447,0.06887332192845741,0.21316280309086064,99.78683719690913
    ~~~
    
    この結果は、分析や、グラフ描画など、様々な使い方ができます。
    
    (注意: 性能測定の結果は様々な要因によって変動します。
    これはあくまで特定のバージョン、特定の環境での結果の例です。)

### 結果の読み方と分析の仕方 {#how-to-analyze}

![スループットのグラフ](/images/tutorial/benchmark/throughput-groonga.png)

先の例と、このグラフを見て下さい。
12クライアントを超えたあたりで、qps値が250前後で頭打ちになっているのを見て取れるでしょう。
これは、計測対象のサービスが1秒あたり最大で250件のリクエストを処理できるということを意味しています。

言い直すと、この結果は「（ハードウェア、ソフトウェア、ネットワーク、データベースの大きさ、クエリの内容など、様々な要素をひっくるめた）このシステムのスループットの性能限界は250qpsである」という風に読み取ることができます。
もしサービスに対するリクエストの件数が増加しつつあり、この限界に近づいているようであれば、クエリの最適化やコンピュータ自体のアップグレードなど、何らかの対策を取ることを検討する必要があると言えます。

また、同じリクエストのパターンをGroongaとDroongaに送ることで、各システムのqps値の上限（性能限界）を比較することができます。
もしDroongaのqps値がGroongaのそれよりも大きい（つまり、DroongaがGroongaよりも高いスループット性能を発揮している）のであれば、サービスのバックエンドをGroongaからDroongaに移行する根拠になり得ます。
また、異なるノード数での結果を比較すると、新しくノードを追加する際のコストパフォーマンスを分析することもできます。


### 比較対照のデータベース（およびそのデータソース）を用意する

もしすでにGroongaベースのサービスを運用しているのであれば、それ自体が比較対照となります。
この場合、Groongaデータベースの内容すべてをダンプ出力し、新しく用意したDroongaクラスタに流し込みさえすれば、性能比較を行えます。

特に運用中のサービスが無いということであれば、有効なベンチマークを取るために大量のデータを格納したデータベースを、対照として用意する必要があります。
[wikipedia-search][]リポジトリには、[Wikipedia日本語版](http://ja.wikipedia.org/)のページを格納したGroongaサーバ（およびDroongaクラスタ）を用意する手助けとなるスクリプトが含まれています。

では、Wikipediaのページを格納したGroongaデータベースを、`192.168.100.50`のノードに準備しましょう。

 1. データベースのサイズを決める。
    ベンチマーク測定のためには、十分に大きいサイズのデータベースを使う必要があります。
    
    * もしデータベースが小さすぎれば、Droongaのオーバーヘッドが相対的に大きくなるため、Droongaにとって過度に悲観的なベンチマーク結果となるでしょう。
    * もしデータベースが大きすぎれば、メモリのスワップが発生してシステムの性能がランダムに劣化するために、過度に不安定なベンチマーク結果となるでしょう。
    * 各ノードのメモリの搭載量が異なる場合、その中で最もメモリ搭載量が少ないノードに合わせてデータベースのサイズを決めるのが望ましいです。

    例えば、`192.168.100.50` (8GB RAM), `192.168.100.51` (8GB RAM), `192.168.100.52` (6GB RAM)の3つのノードがあるとすれば、データベースは6GBよりも小さくするべきです。
 2. [インストール手順](http://groonga.org/ja/docs/install.html)に従ってGroongaサーバをセットアップする。
    
    ~~~
    (on 192.168.100.50)
    % sudo apt-get -y install software-properties-common
    % sudo add-apt-repository -y universe
    % sudo add-apt-repository -y ppa:groonga/ppa
    % sudo apt-get update
    % sudo apt-get -y install groonga
    ~~~
    
    これでGroongaを利用できるようになります。.
 3. Rakeのタスク `data:convert:groonga:ja` を使って、Wikipediaのページのアーカイブをダウンロードし、Groongaのダンプファイルに変換する。
    変換するレコード（ページ）の数は、環境変数 `MAX_N_RECORDS`（初期値は5000）で指定することができます。
    
    ~~~
    (on 192.168.100.50)
    % cd ~/
    % git clone https://github.com/droonga/wikipedia-search.git
    % cd wikipedia-search
    % bundle install
    % time (MAX_N_RECORDS=100000 bundle exec rake data:convert:groonga:ja \
                                   data/groonga/ja-pages.grn)
    ~~~
    
    アーカイブは非常に大きいため、ダウンロードと変換には時間がかかります。
    
    変換が終わったら、`~/wikipedia-search/data/groonga/ja-pages.grn`の位置にダンプファイルが生成されています。
    新しいデータベースを作成し、ダンプファイルの内容を流し込みましょう。
    この操作にも時間がかかります:
    
    ~~~
    (on 192.168.100.50)
    % mkdir -p $HOME/groonga/db/
    % groonga -n $HOME/groonga/db/db quit
    % time (cat ~/wikipedia-search/config/groonga/schema.grn | groonga $HOME/groonga/db/db)
    % time (cat ~/wikipedia-search/config/groonga/indexes.grn | groonga $HOME/groonga/db/db)
    % time (cat ~/wikipedia-search/data/groonga/ja-pages.grn | groonga $HOME/groonga/db/db)
    ~~~
    
    注意: レコードの数がデータベースのサイズに影響します。
    参考までに、検証環境での結果を以下に示します:
    
     * 30万件のレコードから、1.1GBのデータベースができました。
       データの変換には17分、流し込みには6分を要しました。
     * 150万件のレコードから、4.3GBのデータベースができました。
       データの変換には53分、流し込みには64分を要しました。
    
 4. GroongaをHTTPサーバとして起動する
    
    ~~~
    (on 192.168.100.50)
    % groonga -p 10041 -d --protocol http $HOME/groonga/db/db
    ~~~

これで、このノードをベンチマーク測定の対照として使う準備が整いました。


## Droongaクラスタをセットアップする

Droongaをすべてのノードにインストールします。
HTTP経由での動作をベンチマーク測定するので、`droonga-engine`と`droonga-http-server`の両方をインストールする必要があります。

~~~
(on 192.168.100.50)
% host=192.168.100.50
% curl https://raw.githubusercontent.com/droonga/droonga-engine/master/install.sh | \
    sudo HOST=$host bash
% curl https://raw.githubusercontent.com/droonga/droonga-http-server/master/install.sh | \
    sudo ENGINE_HOST=$host HOST=$host PORT=10042 bash
% sudo droonga-engine-catalog-generate \
    --hosts=192.168.100.50,192.168.100.51,192.168.100.52
% sudo service droonga-engine start
% sudo service droonga-http-server start
~~~

~~~
(on 192.168.100.51)
% host=192.168.100.51
...
~~~

~~~
(on 192.168.100.52)
% host=192.168.100.52
...
~~~

注意: `droonga-http-server`をGroongaとは別のポート番号で起動するために、ここでは`PORT`環境変数を使って上記のようにして`10042`のポートで起動するように指定しています。


## GroongaからDroongaへとデータを同期する

次に、Droongaのデータベースを用意します。.
ダンプファイルを元にして、以下のようにDroongaのメッセージを送りましょう:

~~~
(on 192.168.100.50)
% sudo gem install grn2drn
% time (cat ~/wikipedia-search/config/groonga/schema.grn | \
          grn2drn | \
          droonga-send --server=192.168.100.50 \
                       --report-throughput)
% time (cat ~/wikipedia-search/config/groonga/indexes.grn | \
          grn2drn | \
          droonga-send --server=192.168.100.50 \
                       --report-throughput)
% time (cat ~/wikipedia-search/data/groonga/ja-pages.grn | \
          grn2drn | \
          droonga-send --server=192.168.100.50 \
                       --server=192.168.100.51 \
                       --server=192.168.100.52 \
                       --report-throughput)
~~~

スキーマ定義とインデックスの定義については単一のエンドポイントに送るように注意して下さい。
スキーマ定義のリクエストを複数のノードに並行してバラバラに流し込むと、データベースが壊れた状態になる事があります。

この操作にも時間がかかります。
それが完了したら、`10041`ポートを監視するGroonga HTTPサーバと、`10042`ポートを監視するDroonga HTTPサーバの、2つのHTTPサーバがある状態となります。


## クライアントをセットアップする

クライアントにするマシンには、ベンチマーク用のクライアントをインストールする必要があります。

`192.168.100.53`をクライアントとして使うと仮定します:

~~~
(on 192.168.100.53)
% sudo apt-get update
% sudo apt-get -y upgrade
% sudo apt-get install -y ruby curl jq
% sudo gem install drnbench
~~~


## リクエストパターンを用意する

ベンチマーク用のリクエストパターンファイルを用意しましょう。

### キャッシュヒット率を決める

まず、キャッシュヒット率を決める必要があります。

もし既に運用中のGroongaベースのサービスがあるのであれば、以下のようにして、`status`コマンドを使ってGroongaデータベースのキャッシュヒット率を調べることができます:

~~~
% curl "http://192.168.100.50:10041/d/status" | jq .
[
  [
    0,
    1412326645.19701,
    3.76701354980469e-05
  ],
  {
    "max_command_version": 2,
    "alloc_count": 158,
    "starttime": 1412326485,
    "uptime": 160,
    "version": "4.0.6",
    "n_queries": 1000,
    "cache_hit_rate": 0.5,
    "command_version": 1,
    "default_command_version": 1
  }
]
~~~

キャッシュヒット率は`"cache_hit_rate"`として返却されます。
`0.5`は50%という意味で、レスポンスのうちの半分がキャッシュされた結果に基づいて返されているということです。

運用中のサービスが無いのであれば、ひとまずキャッシュヒット率は50％と過程すると良いでしょう。

GroongaとDroongaの性能を正確に比較するためには、キャッシュヒット率が実際の値に近くなるようにリクエストパターンを用意する必要があります。
さて、どのようにすればよいのでしょうか？

キャッシュヒット率は、`N = 100 ÷ (キャッシュヒット率)`という式で計算した、ユニーク（一意）なリクエストパターンの数で制御できます。
これは、GroongaとDroonga（`droonga-http-server`）が既定の状態で最大で100件までの結果をキャッシュするためです。
期待されるキャッシュヒット率が50%なのであれば、用意するべきユニークなリクエストの数は`N = 100 ÷ 0.5 = 200`と計算できます。

### 検索語句のリストを用意する

`drnbench`パッケージは、以下のようなユニークな語句の一覧からベンチマーク用のリクエストパターンを生成する、`drnbench-generate-select-patterns`というユーティリティコマンドを含んでいます:

~~~
AAA
BBB
CCC
~~~

200件のユニークなリクエストパターンを作るには、200個の語句を用意する必要があります。
しかも、それらはすべて実際にGroongaのデータベースで有効な検索結果を返すものでなくてはなりません。
もしランダムに生成した単語（例えば`P2qyNJ9L`, `Hy4pLKc5`, `D5eftuTp`……といった具合）を使った場合、ほとんどのリクエストに対して「ヒット無し」という検索結果が返されてしまうため、有効なベンチマーク結果を得ることができません。

こんな時のために、もう1つ、`drnbench-extract-searchterms`という別のユーティリティコマンドがあります。
これは、以下のようにしてGroongaの検索結果から単語のリストを生成します:

~~~
% curl "http://192.168.100.50:10041/d/select?table=Pages&limit=10&output_columns=title" | \
    drnbench-extract-searchterms
title1
title2
title3
...
title10
~~~

`drnbench-extract-searchterms`は検索結果のレコードの最初の列の値を単語として取り出します。
200件の有効な検索語句を得るには、単に`limit=200`と指定して検索結果を得ればOKです。


### 与えられた語句からリクエストパターンファイルを生成する

それでは、`drnbench-generate-select-patterns`と`drnbench-extract-searchterms`を使って、検索結果からリクエストパターンを生成してみましょう。

~~~
% n_unique_requests=200
% curl "http://192.168.100.50:10041/d/select?table=Pages&limit=$n_unique_requests&output_columns=title" | \
    drnbench-extract-searchterms | \
    drnbench-generate-select-patterns \
    > ./patterns.json
~~~

生成されたファイル `patterns.json` は以下のような内容になります:

~~~
{
  "with-query": {
    "frequency": 1.0,
    "method": "get",
    "patterns": [
      {
        "path": "/d/select?limit=10&offset=0&query=AAA"
      },
      {
        "path": "/d/select?limit=10&offset=0&query=BBB"
      },
      ...
    ]
  }
}
~~~

上の例のように、与えられた単語に基づく`query`パラメータを伴って、`select`コマンド用のリクエストパターンが生成されます。

しかしながら、この生成結果は内容がシンプルすぎます。
テーブルが指定されていませんし、結果の出力も、ドリルダウンの指定もありません。
より有効な検索リクエストを生成するためには、以下のように、`drnbench-generate-select-patterns`コマンドに`--base-params`オプションを使って追加のパラメータを指定します:

~~~
% n_unique_requests=200
% curl "http://192.168.100.50:10041/d/select?table=Pages&limit=$n_unique_requests&output_columns=title" | \
    drnbench-extract-searchterms | \
    drnbench-generate-select-patterns \
      --base-params="table=Pages&limit=10&match_columns=title,text&output_columns=snippet_html(title),snippet_html(text),categories,_key" \
    > ./patterns.json
~~~

すると、以下のようなファイルが生成されます:

~~~
{
  "with-query": {
    "frequency": 1.0,
    "method": "get",
    "patterns": [
      {
        "path": "/d/select?table=Pages&limit=10&match_columns=title,text&output_columns=snippet_html(title),snippet_html(text),categories,_key&query=AAA"
      },
      {
        "path": "/d/select?table=Pages&limit=10&match_columns=title,text&output_columns=snippet_html(title),snippet_html(text),categories,_key&query=BBB"
      },
      ...
    ]
  }
}
~~~


## ベンチマークを実行する

以上で、準備が整いました。
それではGroongaとDroongaのベンチマークを取得してみましょう。

### Benchmark Groonga

First, run benchmark for Groonga as the reference.
Start Groonga's HTTP server before running.

~~~
(on 192.168.100.50)
% groonga -p 10041 -d --protocol http $HOME/groonga/db/db
~~~

You can run benchmark with the command `drnbench-request-response`, like:

~~~
(on 192.168.100.53)
% drnbench-request-response \
    --step=2 \
    --start-n-clients=0 \
    --end-n-clients=20 \
    --duration=30 \
    --interval=10 \
    --request-patterns-file=$PWD/patterns.json \
    --default-hosts=192.168.100.50 \
    --default-port=10041 \
    --output-path=$PWD/groonga-result.csv
~~~

Important parameters are:

 * `--step` is the number of virtual clients increased on each progress.
 * `--start-n-clients` is the initial number of virtual clients.
   Even if you specify `0`, initially one client is always generated.
 * `--end-n-clients` is the maximum number of virtual clients.
   Benchmark is performed progressively until the number of clients is reached to this limit.
 * `--duration` is the duration of each benchmark.
   This should be long enough to average out the result.
   `30` (seconds) seems good for my case.
 * `--interval` is the interval between each benchmark.
   This should be long enough to finish previous benchmark.
   `10` (seconds) seems good for my case.
 * `--request-patterns-file` is the path to the pattern file.
 * `--default-hosts` is the list of host names of target endpoints.
   By specifying multiple hosts as a comma-separated list, you can simulate load balancing.
 * `--default-port` is the port number of the target endpoint.
 * `--output-path` is the path to the result file.
   Statistics of all benchmarks is saved as a file at the location.

Then you'll get the reference result of the Groonga.
After that you should stop Groonga to release CPU and RAM resources.


### Benchmark Droonga

To clear effects from previous benchmark, you should restart services before each test.

~~~
(on 192.168.100.50, 192.168.100.51, 192.168.100.52)
% sudo service droonga-engine restart
% sudo service droonga-http-server restart
~~~

#### Benchmark Droonga with single node

Before benchmarking, make your cluster with only one node.

~~~
(on 192.168.100.50)
% sudo droonga-engine-catalog-generate \
    --hosts=192.168.100.50
~~~

After that the endpoint `192.168.100.50` works as a Droonga cluster with single node.
Run the benchmark.

~~~
(on 192.168.100.53)
% drnbench-request-response \
    --step=2 \
    --start-n-clients=0 \
    --end-n-clients=20 \
    --duration=30 \
    --interval=10 \
    --request-patterns-file=$PWD/patterns.json \
    --default-hosts=192.168.100.50 \
    --default-port=10042 \
    --output-path=$PWD/droonga-result-1node.csv
~~~

Note that the default port is changed from `10041` (Groonga's HTTP server) to `10042` (Droonga).
Moreover, the path to the result file also changed.


#### Benchmark Droonga with two nodes

Before benchmarking, join the second node to the cluster.

~~~
(on 192.168.100.50, 192.168.100.51)
% sudo droonga-engine-catalog-generate \
    --hosts=192.168.100.50,192.168.100.51
~~~

After that both endpoints `192.168.100.50` and `192.168.100.51` work as a Droonga cluster with two nodes.
Run the benchmark.

~~~
(on 192.168.100.53)
% drnbench-request-response \
    --step=2 \
    --start-n-clients=0 \
    --end-n-clients=20 \
    --duration=30 \
    --interval=10 \
    --request-patterns-file=$PWD/patterns.json \
    --default-hosts=192.168.100.50,192.168.100.51 \
    --default-port=10042 \
    --output-path=$PWD/droonga-result-2nodes.csv
~~~

Note that two hosts are specified via the `--default-hosts` option.

If you send all requests to single endpoint, `droonga-http-server` will become a bottleneck, because it works as a single process for now.
Moreover, `droonga-http-server` and `droonga-engine` will scramble for CPU resources.
To measure the performance of your Droonga cluster effectively, you should average out CPU load per capita.

Of course, on the production environment, it should be done by a load balancer, but It's a hassle to set up a load balancer for just benchmarking.
Instead, you can specify multiple endpoint host names as a comma-separated list for the `--default-hosts` option.

And, the path to the result file also changed.


#### Benchmark Droonga with three nodes

Before benchmarking, join the last node to the cluster.

~~~
(on 192.168.100.50, 192.168.100.51)
% sudo droonga-engine-catalog-generate \
    --hosts=192.168.100.50,192.168.100.51,192.168.100.52
~~~

After that all endpoints `192.168.100.50`, `192.168.100.51`, and `192.168.100.52` work as a Droonga cluster with three nodes.
Run the benchmark.

~~~
(on 192.168.100.53)
% drnbench-request-response \
    --step=2 \
    --start-n-clients=0 \
    --end-n-clients=20 \
    --duration=30 \
    --interval=10 \
    --request-patterns-file=$PWD/patterns.json \
    --default-hosts=192.168.100.50,192.168.100.51,192.168.100.52 \
    --default-port=10042 \
    --output-path=$PWD/droonga-result-3nodes.csv
~~~

Note that both `--default-hosts` and `--output-path` are changed again.

## Analyze the result

OK, now you have four results:

 * `groonga-result.csv`
 * `droonga-result-1node.csv`
 * `droonga-result-2nodes.csv`
 * `droonga-result-3nodes.csv`

[As described](#how-to-analyze), you can analyze them.

For example, you can plot a graph from these results like:

![A layered graph of throughput](/images/tutorial/benchmark/throughput-mixed.png)

You can explain this graph as: "On this condition Droonga has better performance when there are multiple nodes", "Single Droonga node's performance is lesser than Groonga's one, on this setting", and so on.

(Note: Performance results fluctuate from various factors.
This graph is just an example on a specific version, specific environment.)

## まとめ

In this tutorial, you did prepare a reference [Groonga][] server and [Droonga][] cluster.
And, you studied how to prepare request patterns, how measure your systems, and how analyze the result.

  [Ubuntu]: http://www.ubuntu.com/
  [CentOS]: https://www.centos.org/
  [Droonga]: https://droonga.org/
  [Groonga]: http://groonga.org/
  [drnbench]: https://github.com/droonga/drnbench/
  [wikipedia-search]: https://github.com/droonga/wikipedia-search/
  [command reference]: ../../reference/commands/
